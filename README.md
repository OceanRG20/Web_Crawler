# Web Crawler â€“ AMBA/Custom Sources

A lightweight Python crawler for extracting company data (name, phone, address, industries, services, employees, etc.) from target websites.  
It outputs results to **CSV** and (optionally) to **Google Sheets**.

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ crawler.py # Main runner
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ urls.txt # Input list of websites
â”‚ â”œâ”€â”€ csv_schema.yaml # Defines CSV columns
â”‚ â””â”€â”€ service_account.json# (Optional) Google Sheets service account
â”œâ”€â”€ extractors/ # HTML/text parsers
â”œâ”€â”€ utils/ # CSV + Sheets utilities
â”œâ”€â”€ output/ # Results (CSV + snapshots)
â”‚ â””â”€â”€ snapshots/ # Timestamped backups
â””â”€â”€ evidence/ # (Optional) Saved HTML/metadata

## âš™ï¸ Requirements

- Python **3.8+**
- Install dependencies:

```bash
pip install -r requirements.txt
```
